@INPROCEEDINGS{wang2011,
author={ {Kai Wang} and B. {Babenko} and S. {Belongie}},
booktitle={2011 International Conference on Computer Vision},
title={End-to-end scene text recognition},
year={2011},
volume={},
number={},
pages={1457-1464},
abstract={This paper focuses on the problem of word detection and recognition in natural images. The problem is significantly more challenging than reading text in scanned documents, and has only recently gained attention from the computer vision community. Sub-components of the problem, such as text detection and cropped image word recognition, have been studied in isolation [7, 4, 20]. However, what is unclear is how these recent approaches contribute to solving the end-to-end problem of word recognition. We fill this gap by constructing and evaluating two systems. The first, representing the de facto state-of-the-art, is a two stage pipeline consisting of text detection followed by a leading OCR engine. The second is a system rooted in generic object recognition, an extension of our previous work in [20]. We show that the latter approach achieves superior performance. While scene text recognition has generally been treated with highly domain-specific methods, our results demonstrate the suitability of applying generic computer vision methods. Adopting this approach opens the door for real world scene text recognition to benefit from the rapid advances that have been taking place in object recognition.},
keywords={computer vision;object recognition;optical character recognition;text detection;end-to-end scene text recognition;word detection;natural images;computer vision community;text detection;image word recognition;OCR engine;object recognition;domain-specific methods;Pipelines;Training;Text recognition;Optical character recognition software;Image recognition;Object recognition;Detectors},
doi={10.1109/ICCV.2011.6126402},
ISSN={2380-7504},
month={Nov},}

@article{Lee2010,
abstract = {In this paper, we propose a framework for isolating text regions from natural scene images. The main algorithm has two functions: it generates text region candidates, and it verifies of the label of the candidates (text or non-text). The text region candidates are generated through a modified K-means clustering algorithm, which references texture features, edge information and color information. The candidate labels are then verified in a global sense by the Markov Random Field model where collinearity weight is added as long as most texts are aligned. The proposed method achieves reasonable accuracy for text extraction from moderately difficult examples from the ICDAR 2003 database.},
author = {Lee, Seong Hun and Cho, Min Su and Jung, Kyomin and Kim, Jin Hyung},
doi = {10.1109/ICPR.2010.969},
file = {:home/Data/home/decker/Unicamp/Mestrado/Artigos/Disserta{\c{c}}{\~{a}}o/Background/Scene Text Extraction with Edge Constraint and Text Collinearity.pdf:pdf},
isbn = {9780769541099},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
mendeley-groups = {Masters-Related Work},
pages = {3983--3986},
title = {{Scene text extraction with edge constraint and text collinearity}},
year = {2010}
}

@article{Kumuda2016,
  title={Hybrid Approach to Extract Text in Natural Scene Images},
  author={Kumuda, T and Basavaraj, L},
  journal={International Journal of Computer Applications},
  volume={142},
  number={10},
  year={2016},
  publisher={Foundation of Computer Science}
}


@article{HyungIlKoo2013,
author = {{Hyung Il Koo}, Hyung Il and {Duck Hoon Kim}, Duck Hoon},
doi = {10.1109/TIP.2013.2249082},
file = {:home/Data/home/decker/Unicamp/Mestrado/Artigos/Disserta{\c{c}}{\~{a}}o/Background/Scene Text Detection via Connected Component Clustering and Non-text Filtering.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
mendeley-groups = {Masters-Related Work},
month = {jun},
number = {6},
pages = {2296--2305},
publisher = {IEEE Press},
title = {{Scene Text Detection via Connected Component Clustering and Nontext Filtering}},
url = {http://ieeexplore.ieee.org/document/6471224/},
volume = {22},
year = {2013}
}

==
@article{Lee2011,
abstract = {Detecting text regions in natural scenes is an important part of computer vision. We propose a novel text detection algorithm that extracts six different classes features of text, and uses Modest AdaBoost with multi-scale sequential search. Experiments show that our algorithm can detect text regions with a f= 0.70, from the ICDAR 2003 datasets which include images with text of various fonts, sizes, colors, alphabets and scripts. {\textcopyright} 2011 IEEE.},
author = {Lee, Jung Jin and Lee, Pyoung Hean and Lee, Seong Whan and Yuille, Alan and Koch, Christof},
doi = {10.1109/ICDAR.2011.93},
file = {:home/Data/home/decker/Unicamp/Mestrado/Artigos/Disserta{\c{c}}{\~{a}}o/Background/AdaBoost for text detection in natural scenes.pdf:pdf},
isbn = {9780769545202},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
keywords = {AdaBoost,text detection,text location},
mendeley-groups = {Masters-Related Work},
pages = {429--434},
title = {{AdaBoost for text detection in natural scene}},
year = {2011}
}


@inproceedings{Coates,
  title={Text Detection and Character Recognition in Scene Images with Unsupervised Feature Learning.},
  author={Coates, Adam and Carpenter, Blake and Case, Carl and Satheesh, Sanjeev and Suresh, Bipin and Wang, Tao and Wu, David J and Ng, Andrew Y},
  booktitle={ICDAR},
  volume={11},
  pages={440--445},
  year={2011}
}



@article{Ng2011,
author = {Wang, Tao and Wu, David J. and Coates, Adam and Ng, Andrew Y.},
file = {:home/Data/home/decker/Unicamp/Mestrado/Artigos/Disserta{\c{c}}{\~{a}}o/Background/End-to-End Text Recognition with Convolutional Neural Networks.pdf:pdf},
journal = {Nips},
mendeley-groups = {Masters-Related Work},
title = {{End-to-End Text Recognition with Convolutional Neural Networks}},
url = {https://papers.nips.cc/paper/4293-selecting-receptive-fields-in-deep-networks.pdf},
year = {2011}
}

@inproceedings{Karatzas2004,
author = {Karatzas, D. and Antonacopoulos, A.},
booktitle = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
doi = {10.1109/ICPR.2004.1334328},
isbn = {0-7695-2128-2},
mendeley-groups = {Masters-Related Work},
pages = {634--637 Vol.2},
publisher = {IEEE},
title = {{Text extraction from Web images based on a split-and-merge segmentation method using colour perception}},
url = {http://ieeexplore.ieee.org/document/1334328/},
year = {2004}
}
@article{Chen2004,
author = {Chen, X. and Yang, J. and Zhang, J. and Waibel, A.},
doi = {10.1109/TIP.2003.819223},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
mendeley-groups = {Masters-Related Work},
month = {jan},
number = {1},
pages = {87--99},
title = {{Automatic Detection and Recognition of Signs From Natural Scenes}},
url = {http://ieeexplore.ieee.org/document/1262016/},
volume = {13},
year = {2004}
}
@article{Nomura2005,
abstract = {This work proposes a novel adaptive approach for character segmentation and feature vector extraction from seriously degraded images. An algorithm based on the histogram automatically detects fragments and merges these fragments before segmenting the fragmented characters. A morphological thickening algorithm automatically locates reference lines for separating the overlapped characters. A morphological thinning algorithm and the segmentation cost calculation automatically determine the baseline for segmenting the connected characters. Basically, our approach can detect fragmented, overlapped, or connected character and adaptively apply for one of three algorithms without manual fine-tuning. Seriously degraded images as license plate images taken from real world are used in the experiments to evaluate the robustness, the flexibility and the effectiveness of our approach. The system approach output data as feature vectors keep useful information more accurately to be used as input data in an automatic pattern recognition system.},
author = {Nomura, Shigueo and Yamanaka, Keiji and Katai, Osamu and Kawakami, Hiroshi and Shiose, Takayuki},
doi = {10.1016/J.PATCOG.2005.01.026},
file = {:Users/decker/Documents/Mendeley Desktop/Nomura et al. - 2005 - A novel adaptive morphological approach for degraded character image segmentation.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
mendeley-groups = {Masters-Related Work},
month = {nov},
number = {11},
pages = {1961--1975},
publisher = {Pergamon},
title = {{A novel adaptive morphological approach for degraded character image segmentation}},
url = {https://www.sciencedirect.com/science/article/pii/S0031320305001251},
volume = {38},
year = {2005}
}

@inproceedings{QixiangYe,
  title={A robust text detection algorithm in images and video frames},
  author={Ye, Qixiang and Gao, Wen and Wang, Weiqiang and Zeng, Wei},
  booktitle={Fourth International Conference on Information, Communications and Signal Processing, 2003 and the Fourth Pacific Rim Conference on Multimedia. Proceedings of the 2003 Joint},
  volume={2},
  pages={802--806},
  year={2003},
  organization={IEEE}
}


@article{Lee2013,
author = {Lee, SeongHun and Kim, Jin Hyung},
doi = {10.1016/j.imavis.2013.08.007},
issn = {02628856},
journal = {Image and Vision Computing},
mendeley-groups = {Masters-Related Work},
month = {nov},
number = {11},
pages = {823--840},
title = {{Integrating multiple character proposals for robust scene text extraction}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0262885613001339},
volume = {31},
year = {2013}
}

@inproceedings{Phan2013,
author = {Phan, Trung Quy and Shivakumara, Palaiahnakote and Tian, Shangxuan and Tan, Chew Lim},
booktitle = {2013 IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2013.76},
isbn = {978-1-4799-2840-8},
mendeley-groups = {Masters-Related Work},
month = {dec},
pages = {569--576},
publisher = {IEEE},
title = {{Recognizing Text with Perspective Distortion in Natural Scenes}},
url = {http://ieeexplore.ieee.org/document/6751180/},
year = {2013}
}
@inproceedings{Buta2015,
author = {Buta, Michal and Neumann, Luka and Matas, Jiri},
booktitle = {2015 IEEE International Conference on Computer Vision (ICCV)},
doi = {10.1109/ICCV.2015.143},
isbn = {978-1-4673-8391-2},
mendeley-groups = {Masters-Related Work},
month = {dec},
pages = {1206--1214},
publisher = {IEEE},
title = {{FASText: Efficient Unconstrained Scene Text Detector}},
url = {http://ieeexplore.ieee.org/document/7410500/},
year = {2015}
}
@article{Almazan2014,
author = {Almazan, Jon and Gordo, Albert and Fornes, Alicia and Valveny, Ernest},
doi = {10.1109/TPAMI.2014.2339814},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
mendeley-groups = {Masters-Related Work},
month = {dec},
number = {12},
pages = {2552--2566},
title = {{Word Spotting and Recognition with Embedded Attributes}},
url = {http://ieeexplore.ieee.org/document/6857995/},
volume = {36},
year = {2014}
}
@inproceedings{Gordo2014,
  title={Supervised mid-level features for word image representation},
  author={Gordo, Albert},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2956--2964},
  year={2015}
}


@inproceedings{Rodriguez-Serrano,
  title={Label embedding for text recognition.},
  author={Rodriguez-Serrano, Jose A and Perronnin, Florent and Meylan, France},
  booktitle={BMVC},
  pages={5--1},
  year={2013},
  organization={Citeseer}
}

@inproceedings{Yao,
  title={Strokelets: A learned multi-scale representation for scene text recognition},
  author={Yao, Cong and Bai, Xiang and Shi, Baoguang and Liu, Wenyu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4042--4049},
  year={2014}
}


@inproceedings{Shi2013,
  title={Scene text recognition using part-based tree-structured character detection},
  author={Shi, Cunzhao and Wang, Chunheng and Xiao, Baihua and Zhang, Yang and Gao, Song and Zhang, Zhong},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2961--2968},
  year={2013}
}


@article{Felzenszwalb2005,
author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
doi = {10.1023/B:VISI.0000042934.15159.49},
file = {:home/decker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Felzenszwalb, Huttenlocher - 2005 - Pictorial Structures for Object Recognition.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
mendeley-groups = {Masters-Related Work},
month = {jan},
number = {1},
pages = {55--79},
publisher = {Kluwer Academic Publishers},
title = {{Pictorial Structures for Object Recognition}},
url = {http://link.springer.com/10.1023/B:VISI.0000042934.15159.49},
volume = {61},
year = {2005}
}


@inproceedings{Neumann2013,
author = {Neumann, Luka and Matas, Jiri},
booktitle = {2013 12th International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2013.110},
isbn = {978-0-7695-4999-6},
mendeley-groups = {Masters-Related Work},
month = {aug},
pages = {523--527},
publisher = {IEEE},
title = {{On Combining Multiple Segmentations in Scene Text Recognition}},
url = {http://ieeexplore.ieee.org/document/6628675/},
year = {2013}
}


@book{Shukla2018,
 author = {Shukla, Nishant},
 title = {Machine Learning with TensorFlow},
 year = {2018},
 isbn = {1617293873, 9781617293870},
 edition = {1st},
 publisher = {Manning Publications Co.},
 address = {Greenwich, CT, USA},
} 

@book{russell2016,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Malaysia; Pearson Education Limited,}
}

@book{bishop2006,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={springer}
}

@article{perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}


@article{vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{googlenet,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@article{deepmethods,
  title={Deep learning: methods and applications},
  author={Deng, Li and Yu, Dong and others},
  journal={Foundations and Trends{\textregistered} in Signal Processing},
  volume={7},
  number={3--4},
  pages={197--387},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@book{goodfellow,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@book{handsonml,
  title={Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems},
  author={G{\'e}ron, Aur{\'e}lien},
  year={2019},
  publisher={O'Reilly Media}
}

@article{logicalcalculus,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}

@article{lenet,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@inproceedings{alexnet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@InProceedings{icdar15,
  Title                    = {ICDAR 2015 competition on Robust Reading},
  Author                   = {D. Karatzas and L. Gomez-Bigorda and A. Nicolaou and S. Ghosh and A. Bagdanov and M. Iwamura and J. Matas and L. Neumann and V. R. Chandrasekhar and S. Lu and F. Shafait and S. Uchida and E. Valveny},
  Booktitle                = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
  Year                     = {2015},
  Month                    = {Aug},
  Pages                    = {1156-1160},

  Doi                      = {10.1109/ICDAR.2015.7333942},
  Keywords                 = {image sequences;text detection;video signal processing;ICDAR 2015 robust reading competition;incidental scene text;born-digital images;focused scene images;video text;text localisation;word recognition;end-to-end pipelines;video sequences;Yttrium;IP networks}
}

@misc{tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@Article{snooper,
  Title                    = {SnooperText: {A} text detection system for automatic indexing of urban scenes},
  Author                   = {Rodrigo Minetto and Nicolas Thome and Matthieu Cord and Neucimar J. Leite and Jorge Stolfi},
  Journal                  = {Computer Vision and Image Understanding},
  Year                     = {2014},
  Pages                    = {92--104},
  Volume                   = {122},

  Bibsource                = {dblp computer science bibliography, https://dblp.org},
  Biburl                   = {https://dblp.org/rec/bib/journals/cviu/MinettoTCLS14},
  Doi                      = {10.1016/j.cviu.2013.10.004},
  Timestamp                = {Sun, 28 May 2017 13:23:21 +0200},
  Url                      = {https://doi.org/10.1016/j.cviu.2013.10.004}
}

@Article{thog,
  Title                    = {{T-HOG}: An effective gradient-based descriptor for single line text regions},
  Author                   = {Rodrigo Minetto and Nicolas Thome and Matthieu Cord and Neucimar J. Leite and Jorge Stolfi},
  Journal                  = {Pattern Recognition},
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {1078--1090},
  Volume                   = {46},

  Bibsource                = {dblp computer science bibliography, https://dblp.org},
  Biburl                   = {https://dblp.org/rec/bib/journals/pr/MinettoTCLS13},
  Doi                      = {10.1016/j.patcog.2012.10.009},
  Timestamp                = {Thu, 18 May 2017 09:54:36 +0200},
  Url                      = {https://doi.org/10.1016/j.patcog.2012.10.009}
}


@article{svm,
	Abstract = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
	Author = {Cortes, Corinna and Vapnik, Vladimir},
	Da = {1995/09/01},
	Date-Added = {2020-02-12 06:44:48 -0300},
	Date-Modified = {2020-02-12 06:44:48 -0300},
	Doi = {10.1007/BF00994018},
	Id = {Cortes1995},
	Isbn = {1573-0565},
	Journal = {Machine Learning},
	Number = {3},
	Pages = {273--297},
	Title = {Support-vector networks},
	Ty = {JOUR},
	Url = {https://doi.org/10.1007/BF00994018},
	Volume = {20},
	Year = {1995},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF00994018}}

@InProceedings{cannyTD,
  Title                    = {Canny Text Detector: Fast and Robust Scene Text Localization Algorithm},
  Author                   = {H. Cho and M. Sung and B. Jun},
  Booktitle                = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  Year                     = {2016},
  Month                    = {June},
  Pages                    = {3566-3573},

  Doi                      = {10.1109/CVPR.2016.388},
  ISSN                     = {1063-6919},
  Keywords                 = {object detection;Canny text detector;scene text localization algorithm;scene text detection algorithm;recall rate;structural information;word-sentence sharing;double threshold;hysteresis tracking;Erbium;Image edge detection;Detectors;Robustness;Hysteresis;Stability criteria;Vegetation}
}

@InProceedings{fastext,
  Title                    = {FASText: Efficient Unconstrained Scene Text Detector},
  Author                   = {M. Buta and L. Neumann and J. Matas},
  Booktitle                = {2015 IEEE International Conference on Computer Vision (ICCV)},
  Year                     = {2015},
  Month                    = {Dec},
  Pages                    = {1206-1214},

  Doi                      = {10.1109/ICCV.2015.143},
  ISSN                     = {2380-7504},
  Keywords                 = {character recognition;feature extraction;image classification;image segmentation;FASText;unconstrained scene text detector;stroke detector;pixel intensity comparison;stroke-specific keypoint detection;text fragment extraction;local thresholding;classification;scene text localization;recognition pipeline;text localization accuracy;Detectors;Lead;Text recognition;Standards;Pipelines;Robustness;Image edge detection}
}


@InProceedings{Neumann2015ICDAR,
  Title                    = {Efficient Scene text localization and recognition with local character refinement},
  Author                   = {L. Neumann and J. Matas},
  Booktitle                = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
  Year                     = {2015},
  Month                    = {Aug},
  Pages                    = {746-750},

  Doi                      = {10.1109/ICDAR.2015.7333861},
  Keywords                 = {character recognition;text detection;scene text localization;scene text recognition;local character refinement;initial text hypothesis detection;region-based method;robust local text model;character detection;Public transportation;Text recognition;Estimation;Google;Image segmentation;Robustness}
}

@INPROCEEDINGS{Smith2007ICDAR,
author={R. Smith}, 
booktitle={Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)}, 
title={An Overview of the Tesseract OCR Engine}, 
year={2007}, 
volume={2}, 
number={}, 
pages={629-633}, 
abstract={The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy, is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier.}, 
keywords={image classification;optical character recognition;Tesseract OCR engine;UNLV;line finding;adaptive classifier;Optical character recognition software;Search engines;Testing;Open source software;Text recognition;Filters;Prototypes;Independent component analysis;Pipelines;Inspection}, 
doi={10.1109/ICDAR.2007.4376991}, 
ISSN={1520-5363}, 
month={Sept},}

@Book{Rousseeuw1987Wiley,
  title     = {Robust Regression and Outlier Detection},
  publisher = {John Wiley \& Sons, Inc.},
  year      = {1987},
  author    = {Rousseeuw, P. J. and Leroy, A. M.},
  address   = {New York, NY, USA},
  isbn      = {0-471-85233-3},
}

@PhdThesis{Shillman1974MIT,
  author  = {Robert J. Shillman},
  title   = {Character Recognition Based on Phenomenological Attributes: Theory and Methods},
  school  = {Massachusetts Institute of Technology},
  year    = {1974},
  type    = {phdthesis},
  address = {Boston, Mass},
}

@article{Blesser1976PR,
title = {Empirical tests for feature selection based on a psychological theory of character recognition},
journal = {Pattern Recognition},
volume = {8},
number = {2},
pages = {77 - 85},
year = {1976},
note = {Pattern Recognition Society Monographs},
issn = {0031-3203},
doi = {https://doi.org/10.1016/0031-3203(76)90036-4},
url = {http://www.sciencedirect.com/science/article/pii/0031320376900364},
author = {Barry A. Blesser and Theodore T. Kuklinski and Robert J. Shillman},
keywords = {Automatic character recognition, Feature detection, Feature selection, Feature testing, Handprint, Human character recognition, Psychology},
abstract = {It is argued that machine algorithms based on feature detection promise the greatest chance for success in the recognition of isolated, unconstrained handprinted characters. In order to match human performance, the features used cannot be chosen in an arbitrary manner; they must have some psychological significance. A theory of characters based on functional attributes is reviewed, and three psychophysical tests are described for determining the psychological validity of any postulated attribute. The first test indicates if a particular attribute is involved in a particular letter, and the second and third tests investigate the commonality of an attribute among different letters.},
}

@INPROCEEDINGS{multilingual,
  author = {N. Sharma and R. Mandal and R. Sharma and P. P. Roy and U. Pal and
    M. Blumenstein},
  title = {Multi-lingual text recognition from video frames},
  booktitle = {2015 13th International Conference on Document Analysis and Recognition
    (ICDAR)},
  year = {2015},
  pages = {951-955},
  month = {Aug},
  abstract = {Text recognition from video frames is a challenging task due to low
    resolution, blur, complex and coloured backgrounds, noise, to mention
    a few. Consequently the traditional ways of text recognition from
    scanned documents having simple backgrounds fails when applied to
    video text. Although there are various techniques available for text
    recognition from handwritten and printed documents with simple backgrounds,
    text recognition from video frames has not been comprehensively investigated,
    especially for multi-lingual videos. In this paper we present a technique
    for multi-lingual video text recognition which involves script identification
    in the first stage followed by word and character recognition and
    finally the results are refined using a post-processing technique.
    Considering the inherent problems in videos, a Spatial Pyramid Matching
    (SPM) based technique, using patch-based S. I. F. T. descriptors
    and SVM classifier, is employed for script identification. In the
    next stage, a Hidden Markov Model (HMM) based approach is used for
    word and character recognition, which utilizes the context information.
    Finally, a lexicon-based post-processing technique is applied to
    verify and refine the word recognition results. The proposed method
    was tested on a dataset comprising of 4800 words from three different
    scripts, namely, Roman (English) Hindi and script identification
    results obtained are encouraging. The word, Bengali. The and character
    recognition results are also encouraging considering the complexity
    and problems associated with video text processing.},
  doi = {10.1109/ICDAR.2015.7333902},
  keywords = {character recognition;hidden Markov models;image classification;image
    matching;support vector machines;transforms;video signal processing;video
    frames;multilingual video text recognition;script identification;character
    recognition;word recognition;spatial pyramid matching;SPM based technique;patch-based
    SIFT descriptors;SVM classifier;hidden Markov model;HMM;lexicon-based
    post-processing technique;Roman;Hindi;Bengali;Hidden Markov models;Character
    recognition;Optical character recognition software;Accuracy;Image
    segmentation;Handwriting recognition},
  review = {This paper presents a technique for multi-lingual video text recognition
    which involves script identification in the first stage followed
    by word and character recognition and finally the results are refined
    using a post-processing technique. Considering the inherent problems
    in videos, a Spatial Pyramid Matching (SPM) based technique, using
    patch-based SIFT descriptors and SVM classifier, is employed for
    script identification. In the next stage, a Hidden Markov Model (HMM)
    based approach is used for word and character recognition, which
    utilizes the context information. Finally, a lexicon-based post-processing
    technique is applied to verify and refine the word recognition results.}
}

@mastersthesis{joselito,
  author  = {José Luis Flores Campana},
  title   = {A comparative study of text detection and recognition approaches for restricted computing scenarios},
  school  = {Universidade Estadual de Campinas},
  year    = {2020},
  type    = {Dissertation},
  address = {Campinas, São Paulo}
}

@ARTICLE{joselito-paper, 
author={J. L. F. {Campana} and A. {Pinto} and M. C. {Neira} and L. G. L. {Decker} and A. {Santos} and J. S. {Conceição} and R. d. S. {Torres}},
journal={IEEE Access},
title={On the Fusion of Text Detection Results: A Genetic Programming Approach},
year={2020},
volume={},
number={},
pages={1-1},
}

@INPROCEEDINGS{manuel, 
author={M. A. {Córdova} and L. G. L. {Decker} and J. L. {Flores-Campana} and A. A. {dos Santos} and J. S. {Conceição}}, 
booktitle={2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)}, 
title={Pelee-Text: A Tiny Convolutional Neural Network for Multi-oriented Scene Text Detection}, 
year={2019}, 
volume={}, 
number={}, 
pages={400-405},}

@conference{decker,
author={Luis Gustavo Lorgus Decker. and Allan da Silva Pinto. and Jose Luis Flores Campana. and Manuel Cordova Neira. and Andreza A. dos Santos. and Jhonatas S. Concei\c{c}ão. and Marcus A. Angeloni. and Lin Tzy Li. and Ricardo da S. Torres.},
title={MobText: A Compact Method for Scene Text Localization},
booktitle={Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 5: VISAPP,},
year={2020},
pages={343-350},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0008954103430350},
isbn={978-989-758-402-2},
}

@inproceedings{jhonny,
 author = {Jhonatas  Conceição and Allan   Pinto and Luis  Decker and Jose Luis Campana and Manuel Neira and Andrezza dos Santos and Helio  Pedrini and Ricardo Torres},
 title = {Multi-Lingual Text Localization via Language-Specific Convolutional Neural Networks},
 booktitle = {Anais Estendidos da XXXII Conference on Graphics, Patterns and Images},
 location = {Rio de Janeiro},
 year = {2019},
 keywords = {},
 issn = {2177-9384},
 pages = {215--218},
 publisher = {SBC},
 address = {Porto Alegre, RS, Brasil},
 doi = {10.5753/sibgrapi.est.2019.8333},
 url = {https://sol.sbc.org.br/index.php/sibgrapi_estendido/article/view/8333}
}
