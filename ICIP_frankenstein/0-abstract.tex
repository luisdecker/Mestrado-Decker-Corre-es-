Multiple research initiatives have been reported to yield highly effective results for the text detection problem, which consists of the challenge of detecting in a digital image if there is a textual element, like a word or a phrase. However, most of those solutions are very costly, thus hampering their use in several applications that rely on the use of devices with restricted processing power, like smartwatches and mobile phones. The text localization is an important step on very widely-used  applications that can be executed on mobile environments, like on-the-go translations and recognition of text for the visually impaired. In this work, we address this issue by investigating the use of efficient object detection networks for this problem. We propose the combination of two light architectures, MobileNetV2 and Single Shot Detector~(SSD), into our proposal MobText for the text detection problem. %Experimental results on the ICDAR'11 and ICDAR'13 datasets demonstrate that our solution yields comparable or superior effectiveness performance than several baselines of the literature, with a low processing cost.
Experimental results in the ICDAR'11 and ICDAR'13 datasets demonstrate that our solution yields the best trade-off between effectiveness and efficiency in terms of processing time, and also achieved the state-of-the-art results in the ICDAR'11 dataset with an f-measure of $96.09\%$ and an average processing time of $464 ms$ on a restricted processing device.  Another contribution of this work relies on the proposal of an evaluation tool to support the assessment of text localization and recognition methods.